---
title: "Inferring the characteristics of rice injury profiles from co-occurrence networks across different geographic locations"
author: "Sith J"
date: "September 30, 2015"
output: html_document
---

# Introduction
#### intro para1 : the background of the survey data 

#### intor para 2


#### intro para 3

#### intro para 4
Here, we use a network approach to infer species roles in the metacommunity structure of a desert ecosystem in the Atacama Desert, Chile. Starting with the incidence matrix of species across local communities, we built a unipartite species network such that any two species that co-occur, more frequently than expected by chance, in local commu- nities were linked. Using this positive co-occurrence network, we: (i) carried out a modularity analysis and classi- fied species into different topological roles; and (ii) tested for the importance of trophic status, body size, numerical abundance and incidence of the species as the biological attributes that could determine these roles. The results herein reported identify modularity as a main component of species co-occurrences networks and, body size and trophic position as chief determinants of the ecological role of species within metacommunities.

# Materials and methods

## survey sites
We conducted the surveys located in the South and South East Asia, Kerala, India(Lat , Long), Indonesia (Lat , Long), Philippines (Lat , Long), Central Plain, Thailand (Lat , Long), and Mekong Delta Vietnam (Lat , Long). Theses are the important rice growing areas, where use irrigated lowland rice ecosystem.  intensive condition, which grow twice per year

```{r echo = TRUE, warning = FALSE, message = FALSE}

library(RCurl) # run this package for load the data form the website 

file <- getURL("https://docs.google.com/spreadsheets/d/1zB7gNdI7Nk7SuHuPWcjzaKnjuwkvL6sOVMo0zMfuV-c/pub?gid=558862364&single=true&output=csv") # load data from the google drive

data <- read.csv(text = file) # read data which is formated as the csv

```
 

```{r survey data}
  library(ggmap)
  mapgilbert <- get_map(location = c(lon = mean(mark.data$Long), lat = mean(mark.data$Lat)), zoom = 4, maptype = "satellite", scale = 2)
  
  ggmap(mapgilbert) +
    geom_point(data = mark.data, aes(x = Long, y = Lat, fill = "red", alpha = 0.8), size = 3, shape = 21) +
    guides(fill = FALSE, alpha = FALSE, size = FALSE)
#library(rworldmap)
#names(data)
#mark.data <- data[, names(data) %in% c("Fno", "Lat", "Long")]
#map <- get_map(location = "India and Southeast Asia", zoom = 4)
#newmap <- getMap(resolution = "low")
#plot(newmap, xlim = c(70, 120), ylim = c(-10, 20), asp = 1)
#points(mark.data$Long, mark.data$Lat, col = "red", cex = .6)
```


## Here is the report of the network analysis of the crop health data.

```{r loading the libraries, echo = TRUE, warning = FALSE, message = FALSE}
library(dplyr)
library(plyr)
library(reshape)
library(reshape2)
library(gridExtra)
library(lubridate)
library(doBy)
library(cluster)
library(ggplot2)
library(scales)
library(bioDist)
library(vegan)
library(mvtnorm)
library(igraph)
library(WGCNA)
library(cowplot)
library(NMF)
```

Load the survey data





```{r define the NA}

data[data == "-"] <- NA # replace '-' with NA

data[data == ""] <- NA # replace 'missing data' with NA

#==== to lower variable names ====
names(data) <- tolower(names(data)) # for more consistancy
```

select out the column which is not inlcuded in the analysis

```{r select out}
# remove the variables that are not included for analysis
data$phase <- NULL # there is only one type yype of phase in the survey
data$identifier <- NULL # this variable is not included in the analysis
data$village <- NULL # remove name of village
data$year <- NULL # remove year data
data$season <- NULL # remove season data
data$lat <- NULL # remove latitude data
data$long <- NULL # remove longitude data
data$fa <- NULL # field area is not include in the analysis
data$fn <- NULL # farmer name can not be included in this survey analysis
data$fp <- NULL # I do not know what is fp
data$lfm <- NULL # there is only one type of land form in this survey
data$ced <- NULL # Date data can not be included in the network analysis
data$cedjul <- NULL # remove crop establisment julian date data
data$hd <- NULL # Date data can not be included in the network analysis
data$hdjul <- NULL # remove harvest julian date
data$cvr <- NULL # reove crop varieties
data$varcoded <- NULL # I will recode them 
data$fymcoded <- NULL # remove code data of fym
data$mu <- NULL # no record of mullucicide data
data$nplsqm <- NULL # remove number of plant per square meter
data$rbpx <- NULL # no record of rice bug p
```


```{r}
#==== corract the variable type =====
# reformat of the vaibales
data <- transform(data, 
                  country = as.factor(country),
                  pc = as.factor(pc),
                  cem = as.factor(cem),     
                  ast = as.factor(ast),       
                  ccd = as.numeric(ccd),
                  vartype = as.factor(vartype),
                  fym = as.character(fym),
                  n = as.numeric(n),
                  p = as.numeric(p) ,
                  k = as.numeric(k),
                  mf = as.numeric(mf),        
                  wcp = as.factor(wcp),      
                  iu = as.numeric(iu),     
                  hu = as.numeric(hu),      
                  fu = as.numeric(fu),      
                  cs  = as.factor(cs),      
                  ldg  =  as.numeric(ldg),  
                  yield = as.numeric(yield) ,
                  dscum = as.factor(dscum),   
                  wecum = as.factor(wecum),   
                  ntmax = as.numeric(ntmax), 
                  npmax = as.numeric(npmax),    
                  nltmax = as.numeric(nltmax),  
                  nlhmax = as.numeric(nltmax),  
                  waa = as.numeric(waa),      
                  wba = as.numeric(wba) ,   
                  dhx =  as.numeric(dhx),  
                  whx =  as.numeric(whx),     
                  ssx  = as.numeric(ssx),  
                  wma = as.numeric(wma), 
                  lfa = as.numeric(lfa),
                  lma = as.numeric(lma),   
                  rha  = as.numeric(rha) ,
                  thrx = as.numeric(thrx),    
                  pmx = as.numeric(pmx),    
                  defa  = as.numeric(defa) ,
                  bphx = as.numeric(bphx),   
                  wbpx = as.numeric(wbpx),    
                  awx  = as.numeric(awx), 
                  rbx =as.numeric(rbx),   
                  rbbx = as.numeric(rbbx),  
                  glhx  = as.numeric(glhx), 
                  stbx=as.numeric(stbx),    
                  hbx= as.numeric(hbx),
                  bbx = as.numeric(bbx),    
                  blba = as.numeric(blba),    
                  lba = as.numeric(lba),    
                  bsa = as.numeric(bsa),    
                  blsa = as.numeric(blsa),  
                  nbsa = as.numeric(nbsa),  
                  rsa  = as.numeric(rsa),   
                  lsa = as.numeric(lsa),    
                  shbx = as.numeric(shbx) ,  
                  shrx = as.numeric(shrx),    
                  srx= as.numeric(srx),    
                  fsmx = as.numeric(fsmx),   
                  nbx =  as.numeric(nbx),   
                  dpx = as.numeric(dpx),    
                  rtdx  = as.numeric(rtdx),  
                  rsdx  = as.numeric(rsdx),
                  gsdx  =as.numeric(gsdx),   
                  rtx = as.numeric(rtx)
) 
```

Now data are in the right format and ready to further analysis, but there are some variables needed to code as the number not character

Before proforming cluster analysis which is the further analysis, I need to code the character to number

##### recode the previous crop

if previosu crop data are rice, they will be coded as 1, but others, not rice, they will be coded as 0.
```{r recoding previous crop}
data$pc <- ifelse(data$pc == "rice", 1, 0)
```

##### recode the crop establisment mothods
Transplanting rice is 1, and direct seeded rice is 2.

```{r coding the data1}
#Crop establisment method
levels(data$cem)[levels(data$cem) == "trp"] <- 1
levels(data$cem)[levels(data$cem) == "TPR"] <- 1
levels(data$cem)[levels(data$cem) == "DSR"] <- 2
levels(data$cem)[levels(data$cem) == "dsr"] <- 2
```

##### fym

fym there are two type 0 and 1, raw data are recorded as no, yes, and value, if the value is 0 which mean 0 and if the value more than 0 which means 1 

```{r coding the data2}

data$fym <- ifelse(data$fym == "no", 0, 
                   ifelse(data$fym == "0", 0, 1
                   )
)
```

##### Vartype

Vartype there are three type treditional varieties coded as 1, modern varities coded as 2 and hybrid coded as 3.

```{r coding the data3}
data$vartype <- ifelse(data$vartype == "tv", 1,
                       ifelse(data$vartype == "mv", 2,
                              ifelse(data$vartype == "hyb", 3, NA
                              )
                       )
)

```

##### Weed control practices
Weed management practices have three type, hand coded as 1, herb coded as 2, and herb-hand coded as 3.

```{r coding the data4}

# wcp weed control management
levels(data$wcp)[levels(data$wcp) == "hand"] <- 1

levels(data$wcp)[levels(data$wcp) == "herb"] <- 2

levels(data$wcp)[levels(data$wcp) == "herb-hand"] <- 3

```

##### Crop status
Crop status have five level, very poor coded as 1, poor coded as 2, average coded as 3, good coded as 4 and very good coded as 5.

```{r coding the data5}
# Crop Status
levels(data$cs)[levels(data$cs) == "very poor"] <- 1

levels(data$cs)[levels(data$cs) == "poor"] <- 2

levels(data$cs)[levels(data$cs) == "average"] <- 3

levels(data$cs)[levels(data$cs) == "good"] <- 4

levels(data$cs)[levels(data$cs) == "very good"] <- 5

```

### Pre-process before performing cluster analysis
all data should be numeric data

```{r}
#clean the data
num.data <- apply(data[, -c(1,2)], 2, as.numeric) # create dataframe to store the numerical transformation of raw data excluded fno and country

num.data <- as.data.frame(as.matrix(num.data)) # convert from vector to matrix

data <- cbind(data[ , c("fno", "country")], num.data)

data <- data[ , apply(data[, -c(1,2)], 2, var, na.rm = TRUE) != 0] # exclude the column with variation = 0

data <- data[complete.cases(data), ] # exclude row which cantain NA

```

## Cluster analysis of the production sitation

Cluster analyses using a nearest neighbor and a chi-square distance (15) were performed in subsets representing each site, in order to determine site-specific patterns of cropping practices and injury profiles. Clusters including less than n = 3 fields were disregarded from further steps.
Cluster analysis can be applied to categorized data, and in this case with a chi-square distance. 

Cluster analysis allows groups of plots haring similar chacteristics to be identified. It was used here to define clusters of injury types in a way similar to that used in the analysis of surveys. One feature is that this technique, when applied to results from factorially arranged experiments, generate clusters where one injury type often tend to predominate. One result from cluster analysis is that inclusion of one individual to a particular cluster can be seen as a new, synthetic variable. Each plot, therefore, can then be described as one element of a given cluster of injury type, where often one injury predominates.

1. subset productio situation data

```{r subset production situation data}

start.PS <- "pc"

end.PS <- "fu"

start.col.PS <- match(start.PS, names(data))

end.col.PS <- match(end.PS, names(data))

PS.data <- data[, c(1, start.col.PS:end.col.PS)]
```

2. clustering the variables related to production situation by Eclidean distanct
```{r }
#distance matrix
dist.PS <- daisy(PS.data[-1]) # Dissimilarity Matrix Calculation from cluster library, "grower" method can handel the mix variables.

cluster.PS <- hclust(dist.PS, method = "average")

dendro.PS <- as.dendrogram(cluster.PS)

plot(dendro.PS, center = T, nodePar = list(lab.cex = 0.6, lab.col = "black", pch = NA), main = "Dendrogram for Production situation")

# draw retangles
rect.hclust(tree = cluster.PS, k=2, border = c("red", "blue"))
```

Here is the heatmap and dendrogram showing that Nitrogen is the big influence to seperate the observation into two groups.

```{r}
aheatmap(subset(PS.data, select = -c(fno, mf)), distfun = daisy, hclustfun = "average")
```

We realized that the total number of observation of surveys are 420. If we have many clusters, It will affect of reliability of the results because the number of observations is small. So we decided to cluster into two groups. 

```{r define which onbservation}
#number of members in each cluster
PS.no <- cutree(cluster.PS, k = 2) #

# cophenitic correlation
rcluster.PS <- cophenetic(cluster.PS) # identify which observation drop in which groups

#cor(dist.PS, rcluster.PS) # Cophenetic correlation is an measure of how faitfully a dendrogram perserves the pairwise distance between the original unmodeled points
# It should be very close to 1 for a high-quality solution.

data <- cbind(data, PS.no) # add to this data into the raw data set

data$PS.no <- as.factor(data$PS.no) # define this value as the factor

```

### Exploration of the profiles of production situtation in grop 1 and group 2


##### How many observation of each country ?

```{r}
g <- ggplot(data, aes(x = country)) +
  
  geom_histogram(weights = count) +
  
  stat_bin(geom = "text", aes(label = ..count..), vjust = 1.5, color = "white" ) +
 
   scale_y_continuous(limits = c(0, 125), breaks = NULL ) +
  
  theme(legend.position = "none") +
  
  ggtitle("The no of observation of dataset in each country")

print(g)
```



1. create the data subseted by country because we would rather to know the difference between cluster 1 and 2 in same country.

```{r}
name.country <- c("IDN", "IND", "THA", "VNM", "PHL") #sort(as.vector(unique(groups)))

by.country.data <- list()

for(i in 1:length(name.country)){
  
  temp <- data %>% filter(country == name.country[i])
  
  by.country.data[[i]] <- temp
  
}
```

#### How many obervations in each group in each country?

```{r bunch_o_figs_svg, fig.height = 4, fig.width = 4, dev='svg'}
par(mfrow=c(1, 2))
for(i in 1:length(name.country)) {
  
  g <- ggplot(by.country.data[[i]], aes(x = PS.no)) +
    
    geom_histogram(weights = count) +
    
    ggtitle(paste("Histogram PS cluster of", name.country[i])) +
    
    theme(legend.position="none")

  print(g)   

  }
```

2. explore the distribution of each variable in differnt grups of production sitaion sepreated by country.

```{r}
# The profile of PS no 
clus.PS.data <- data[, -c(1, 17:56)] # select only the production sitation data

m.PS.data <- melt(clus.PS.data)

name.variable <- levels(m.PS.data$variable)

name.PS.no <- levels(m.PS.data$PS.no)
```


```{r fig.height = 4, fig.width = 4, dev='svg'}
# check the profile of each cluster by histogram 
layout(matrix(c(1:14), 14, 2, byrow = TRUE))
for(i in 1:length(name.variable)) {
  
  subtemp <- subset(m.PS.data, variable == name.variable[i])
 
   for(j in 1: length(name.PS.no)){
     subtemp1 <- subtemp %>% filter(PS.no == name.PS.no[j])
     
     g <-  ggplot(subtemp1, aes(x = value)) +
       
       geom_bar(aes(y = (..count..)/sum(..count..)), binwidth = 1) + 
       
       scale_y_continuous(limits = c(0, 1), labels = percent) + 
       
       ylab("Percent") + xlab(paste(name.variable[i])) +
       
       ggtitle(paste("Histogram of", name.variable[i], "in PS. no", name.PS.no[j]))

     print(g) # the normal rscript do not need to use print function for express graph but here is rknit 
     
   }
  
  }
```


```{r}
#head(data)
# select only the variables related to the injury profiles

start.IP <- "dhx" # set to read the data from column named "dhx"

end.IP <- "rtx" # set to read the data from column named "rtx"

start.col.IP <- match(start.IP, names(data)) # match function for check which column of the data mactch the column named following the conditons above

end.col.IP <- match(end.IP, names(data)) # match function for check which column of the data mactch the column named following the conditons above

IP.data <- data[start.col.IP:end.col.IP] # select the columns of raw data which are following the condition above

#==== pre-process before run correlaiton function
# because the correlaiton measures will not allow to perform with variables whihc have not variance.

IP.data <- IP.data[ ,apply(IP.data, 2, var, na.rm = TRUE) != 0] # exclude the column (variables) with variation = 0

groups <- paste(data$country, data$PS.no, sep = "_") #combine two cloumn names country and PS

IP.data <- cbind(groups, IP.data)

IP.data[is.na(IP.data)] <- 0

trts <- as.vector(unique(IP.data$groups))
```

### Co-occurence Analysis

The first step in the analysis  is identify outlier sample using absolute hierarchical cluster analysis. After removing the outliers for analysis we would construct a weight networking weight

The analysis presented in this paper is desigened to capture the co-occurence patterns of pest injuries, weed infastratioon and disease wiht in geographoical levelos that are consistance. We considered both posisitve and negative co-occurence, whcih are from ranbks correlaitons (Spearman's correaltion) between pair of a injury within ach sataset with the strangth of relationshop represent by tghe correlation coefficent. Negative correaltions (indicative of adverse occurence) were also inclused in this analsusis though thet were a samll suybetr of our combined datasets. We only considered negative and positive co-occruence relationship of correaltion coefficients where $p$-values less than p = 0.05.


Spearman's correlation was used because it only check if two injuries are monotonically related, rather than having a linear relationship. As a result is less sensitive to difference in abundance, and this was desireable because abundance information may have . We employed Spearman correlation coefficents since distribution of the injuiores profiuels daa os 8unknow and ften does not satisfy the notmality condition.
I should rtake nothe definition of the value that we collected in the surveys Co-occurence was assessed using a previosuly descripted methos

```{r, warning= FALSE, message=FALSE}
#=====co_occurrence_pairwise.R====
country.results <- matrix(nrow = 0, ncol = 7) #  assign country.results storing pairwise Spearman's rank correlation by country

options(warnings = -1) # setting not to show the massages as the warnings

for(a in 1:length(name.country)){
  # subset the raw data by groups of countries and cluster of production situation
  country.temp <- name.country[a]
  #subset the dataset for those treatments
  temp <- subset(IP.data, country == country.temp)
  
  #in this case the community data started at column 6, so the loop for co-occurrence has to start at that point
  for(b in 2:(dim(temp)[2]-1)){
    #every species will be compared to every other species, so there has to be another loop that iterates down the rest of the columns
    for(c in (b + 1):(dim(temp)[2])){
      
      #summing the abundances of species of the columns that will be compared
      species1.ab <- sum(temp[,b])
      
      species2.ab <- sum(temp[,c])
      #if the column is all 0's no co-occurrence will be performed
      if(species1.ab > 1 & species2.ab > 1){
        
        test <- cor.test(temp[,b], temp[,c], method = "spearman", na.action = na.rm, exact = FALSE)
        # There are warnings when setting exact = TRUE because of ties from the output of Spearman's correlation
        # stackoverflow.com/questions/10711395/spear-man-correlation and ties
        # It would be still valid if the data is not normally distributed.
       
         rho <- test$estimate
        
         p.value <- test$p.value
      }
      
      if(species1.ab <=1 | species2.ab <= 1){
       
         rho <- 0
        
        p.value <- 1
      }	
      
      new.row <- c(trts[a], names(temp)[b], names(temp)[c], rho, p.value, species1.ab, species2.ab)
      
      results <- rbind(results, new.row)			
      
    }
    
  }
 
   print(a/length(trts))
  
}

country.results <- data.frame(data.matrix(country.results))

names(country.results) <- c("trt","taxa1","taxa2","rho","p.value","ab1","ab2")

#making sure certain variables are factors
country.results$country <- as.factor(country.results$country)
country.results$taxa1 <- as.character(as.factor(country.results$taxa1))
country.results$taxa2 <- as.character(as.factor(country.results$taxa2))
country.results$rho <- as.numeric(as.character(country.results$rho))
country.results$p.value <- as.numeric(as.character(country.results$p.value))
country.results$ab1 <- as.numeric(as.character(country.results$ab1))
country.results$ab2 <- as.numeric(as.character(results$ab2))

head(country.results)
```

```{r}
  results_sub <- subset(results, as.numeric(as.character(abs(rho))) > 0.25)

  results_sub.by.group <- list()

  name.groups <- name.groups <- c("IDN_1", "IDN_2", "IND_1", "IND_2", "THA_1", "THA_2", "VNM_1", "VNM_2", "PHL_1") #sort(as.vector(unique(groups)))
```

### Network constuction and analysis 

Co-occurrence networks were produced by applying an association metric or correlation coefficient to the simulated abundance data in a pair-wise manner. Statistically significant aggregation or avoidance was determined by generating a null distribution for each species pair by shuffling the site-abundance of one of the species and re-calculating the association metric. This resampling was performed 1000 times and the resulting distribution was used to generate p-values for observed association metric. P-values were corrected for multiple comparisons using the method of Benjamini and p-values less than p = 0.05 were considered to be statistically significant edges in the network. The sparCC program (Friedman and Alm, 2012), which was used for treatment of relative abundance data, uses a similar approach based on matrix permutation and null distribution generation.

```{r fig.height = 4, fig.width = 4, dev='svg'}
  for(i in 1: length(name.groups)){
  
  results_sub.by.country[[i]] <- subset(results_sub, country == name.country[i])
  }
```


```{r fig.height = 5, fig.width = 5, dev='svg'}
# head(results_sub.by.group[[1]][,2:3]) # get the list
#layout(matrix(c(1:14), 9, 2, byrow = TRUE))
  cnet  <- list()

for(i in 1:length(name.groups)){
  
  g[[i]] <- graph.edgelist(as.matrix(results_sub.by.group[[i]][, 2:3]), directed = FALSE)
#== adjust layout

  l <- layout.circle(g[[i]])
#== adjust vertices
  V(g[[i]])$color <- "tomato"
  V(g[[i]])$frame.color <- "gray40"
  V(g[[i]])$shape <- "circle"
  V(g[[i]])$size <- 25
  V(g[[i]])$label.color <- "white"
  V(g[[i]])$label.font <- 2
  V(g[[i]])$label.family <- "Helvetica"
  V(g[[i]])$label.cex <- 0.7

#== adjust the edge
  E(g[[i]])$weight <- as.matrix(results_sub.by.group[[i]][, 4])
  
  E(g[[i]])$width <- 1 + E(g[[i]])$weight*5
  
  col <- c("firebrick3", "forestgreen")
  
  colc <- cut(results_sub.by.group[[i]]$rho, breaks = c(-1, 0, 1), include.lowest = TRUE)
  
  E(g[[i]])$color <- col[colc]

#== plot network model
  plot(g[[i]], layout = l * 1.0, main = paste( "network model of", name.groups[i]))
}
```


```{r}

  network.value <- list()

for(i in 1:length(g)){

  E(g[[i]])$weight <- as.matrix(abs(results_sub.by.group[[i]][, 4]))

  network.value[[i]] <- data.frame(
  id = V(g[[i]])$name, 
  deg = degree(g[[i]]), # degree
  bet = betweenness(g[[i]]), # betweenness
  clo = closeness(g[[i]]), # closeness
  eig = evcent(g[[i]])$vector,# egin.cent
  cor = graph.coreness(g[[i]]), # coreness
  tra = transitivity(g[[i]], type = c("local")) # cluster coefficients
)

  network.value[[i]]$res <- as.vector(lm(eig ~ bet, data = network.value[[i]])$residuals)
  network.value[[i]]$group <- name.groups[i]
}

  net.vertice.data <- as.data.frame(do.call("rbind", network.value))
  row.names(net.vertice.data) <- NULL
```










```{r}
  net.vertice.data$id <- as.factor(net.vertice.data$id)
  net.vertice.data$group <- as.factor(net.vertice.data$group)
  m.net.vertice.data <- melt(net.vertice.data)
```


```{r}
# compare degree

  m.net.vertice.data %>% filter(variable == "deg") %>% 
   ggplot(aes(x= value, y = id)) + 
        geom_point(size = 3, color ="blue") +
   facet_wrap(~group) +
        theme_bw() +
        theme(panel.grid.major.x =  element_blank(),
              panel.grid.minor.x =  element_blank(),
              panel.grid.major.y = element_line(color = "grey", linetype = 3)) +
  ggtitle("Degree of each node in the injury profile network")
```


```{r}
  m.net.vertice.data %>% filter(variable == "bet") %>% 
   ggplot(aes(x= value, y = id)) + 
        geom_point(size = 3, color ="blue") +
   facet_wrap(~group) +
        theme_bw() +
        theme(panel.grid.major.x =  element_blank(),
              panel.grid.minor.x =  element_blank(),
              panel.grid.major.y = element_line(color = "grey", linetype = 3)) +
   ggtitle("Betweenness of each node in the injury profile network")
```

```{r}
 m.net.vertice.data %>% filter(variable == "bet") %>% 
   ggplot(aes(x= value, y = id)) + 
        geom_point(size = 3, color ="blue") +
   facet_wrap(~group) +
        theme_bw() +
        theme(panel.grid.major.x =  element_blank(),
              panel.grid.minor.x =  element_blank(),
              panel.grid.major.y = element_line(color = "grey", linetype = 3)) +
   ggtitle("Betweenness of each node in the injury profile network")
```

```{r}
m.net.vertice.data %>% filter(variable == "clo") %>% 
   ggplot(aes(x= value, y = id)) + 
        geom_point(size = 3, color ="blue") +
   facet_wrap(~group) +
        theme_bw() +
        theme(panel.grid.major.x =  element_blank(),
              panel.grid.minor.x =  element_blank(),
              panel.grid.major.y = element_line(color = "grey", linetype = 3)) +
   ggtitle("Closeness of each node in the injury profile network")
```

```{r}
m.net.vertice.data %>% filter(variable == "eig") %>% 
   ggplot(aes(x= value, y = reorder(id, value))) + 
        geom_point(size = 3, color ="blue") +
   facet_wrap(~group) +
        theme_bw() +
        theme(
              panel.grid.major.x =  element_blank(),
              panel.grid.minor.x =  element_blank(),
              panel.grid.major.y = element_line(color = "grey", linetype = 3)
              ) +
   ggtitle("Eigenvector of each node in the injury profile network")
```

```{r}
m.net.vertice.data %>% filter(variable == "cor") %>% 
   ggplot(aes(x= value, y = reorder(id, value))) + 
        geom_point(size = 3, color ="blue") +
   facet_wrap(~group) +
        theme_bw() +
        theme(
              panel.grid.major.x =  element_blank(),
              panel.grid.minor.x =  element_blank(),
              panel.grid.major.y = element_line(color = "grey", linetype = 3)
              ) +
   ggtitle("Eigenvector of each node in the injury profile network")

```


One method is to plot / regress eigenvector centrality on betweenness and examine the residue.

- A variable or node with high betweenness and low eigenvector centrality may be an importanct gatkeeper to a central actor

- A variable or node with low betweeness and hight eigenvector centrality may have unique access to central actor

```{r plot BtnVSEgv, fig.height = 5, fig.width = 5, dev='svg' }
layout(matrix(c(1:9), 5, 2, byrow = TRUE))
for(i in 1:length(network.value)){
 plot <- ggplot(
  network.value[[i]], aes(x = bet, y = eig,
               label = rownames(network.value[[i]]),
               color = res,
               size = abs(res))) +
    xlab("Betweenness Centrality") +
    ylab("Eigencvector Centrality") +
    geom_text() +
    ggtitle(paste("Key Actor Analysis for Injuiry Profiles of", name.groups[i]))

print(plot) 
}
```














```{r Network prop}
# dd <- degree.distribution(g[[1]], cumulative = T, mode = "all")
# plot(dd, pch = 19, cex = 1, col = "orange", xlab = "Degree", ylab = "Cumulative Frequesncy")
# distances(g[[1]])
# #shortest_paths(g[[1]], 5)
# all_shortest_paths(g[[1]], 1, 6:8)
# mean_distance(g[[1]])
# hist(degree(g[[1]]),  col = "lightblue", xlim = c(0, 10), xlab = "Vertex Degree", ylab = "Frequency", main = "")
# hist(graph.strength(g[[1]]),  col = "pink", xlim = c(0, 5), xlab = "Vertex strength", ylab = "Frequency", main = "")

#global.prop <- NULL
#i <-1
#for(i in 1:length(g)){
#adj.mat <- as.matrix(get.adjacency(g[[i]], attr = "weight"))
#new.global.prop <- as.data.frame(fundamentalNetworkConcepts(adj.mat))
#names(new.global.prop) <- name.groups[i]
#global.prop <- c(global.prop, new.global.prop)
#net.result <- fundamentalNetworkConcepts(mat[[i]])
#conformityBasedNetworkConcepts(mat)
#}
#sum.global <- as.data.frame(do.call("cbind", global.prop))
#rownames(sum.global) <- c("Density", "Centralization", "Heterogeneity", "Mean ClusterCoef", "Mean Connectivity")
```


```{r}
# cleate all the possible pair of the variables
# IP.list <- NULL
#   for(i in 2:(dim(IP.data)[2]-1)){
#      for(j in (i+1):(dim(IP.data)[2])){
#       new.row <- c(names(IP.data)[i], names(IP.data)[2 + j])
#       IP.list <- rbind(IP.list, new.row)			
#     }
#   }
# 
# IP.list <- as.data.frame(IP.list)
# names(IP.list) <- c("var1", "var2")
# IP.list$rho <- 0
```


```{r}
# results$newrho <- ifelse(abs(results$rho) > 0.25, results$rho, 0)
#  
# IDN1 <- results %>% filter(trt == "IDN_1")
#  IDN2 <- results %>% filter(trt == "IDN_2")
#  IND1 <- results %>% filter(trt == "IND_1")
#  IND2 <- results %>% filter(trt == "IND_2")
#  THA1 <- results %>% filter(trt == "THA_1")
#  THA2 <- results %>% filter(trt == "THA_2")
#  VNM1 <- results %>% filter(trt == "VNM_1")
#  VNM2 <- results %>% filter(trt == "VNM_1")
#  PHL1 <- results %>% filter(trt == "PHL_1")

```


